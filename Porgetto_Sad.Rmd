---
title: "Report SAD"
author: "Genito e Leone"
date: "2023-02-20"
output:
  pdf_document: default
  html_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

***`VEDI SE RIESCI AD INFILARCI LA LEGGE DI PARETO perché il 20% dei marchi hanno l'80% del mercato nella var manufacturer`***

# Dati sull'efficienza del carburante dal 1999 al 2008 per 38 modelli di auto popolari

## Descrizione

Il dataset "mpg" (Miles per Gallon) fornito con il pacchetto
**`ggplot2`** in R contiene informazioni sull'efficienza del carburante
di diverse automobili. Il dataset include le seguenti variabili:

-   **`manufacturer`**: il produttore dell'automobile.

-   **`model`**: il modello dell'automobile.

-   **`displ`**: il volume dei cilindri dell'automobile, in litri.

-   **`year`**: l'anno di produzione dell'automobile.

-   **`cyl`**: il numero di cilindri dell'automobile.

-   **`trans`**: il tipo di trasmissione dell'automobile.

-   **`drv`**: il tipo di trazione dell'automobile (anteriore,
    posteriore o integrale).

-   **`cty`**: il consumo di carburante in città, in miglia per gallone.

-   **`hwy`**: il consumo di carburante in autostrada, in miglia per
    gallone.

-   **`fl`**: il tipo di carburante utilizzato dall'automobile.

-   **`class`**: la classe di dimensioni dell'automobile.

Il dataset "mpg" è composto da 234 osservazioni, una per ogni automobile
presente nel dataset. Utilizziamo questo dataset per esplorare la
relazione tra l'efficienza del carburante e diverse caratteristiche
delle automobili, come il produttore, il modello, il volume dei cilindri
o il tipo di trasmissione.

# Esplorazione dei dati

## Installazione del pacchetto ggplot2

Il primo passo è installare il pacchetto **`ggplot2`** utilizzando il
comando **`install.packages("ggplot2")`** e quindi caricarlo in R
utilizzando il comando **`library(ggplot2)`**.

## Caricamento delle librerie

```{r include=FALSE}
library(ggplot2)
library(plotly)
library(dplyr)
library(tidyverse)
library(caret)
library(stats)
library(cluster)
library(GGally)

```

## Import del dataset

Eseguiamo il comando **`data(mpg)`** per caricare il dataset "mpg" in
memoria.

```{r}
data(mpg)

```

## Panoramica del dataset

Utilizziamo il comando **`head(mpg)`** per visualizzare le prime
osservazioni del dataset. Questo ci darà un'idea di come sono
strutturati i dati e delle variabili incluse nel dataset.

```{r}
head(mpg)

```

Il comando **`head()`** è utile per esplorare i dati e avere una
panoramica delle osservazioni presenti nel dataset. Vogliamo
visualizzare anche le ultime osservazioni del dataset, quindi
utilizziamo il comando **`tail(mpg)`**.

```{r}
tail(mpg)

```

Vogliamo visualizzare un numero specifico di osservazioni, quindi
utilizziamo il comando **`head(mpg, n)`**, dove **`n`** è il numero di
osservazioni che vogliamo visualizzare.

```{r}
head(mpg, 10)

```

## Pulizia dei dati

La pulizia dei dati consiste nel processo di verifica e correzione dei
dati contenuti in un dataset al fine di garantirne la qualità e la
validità per un'analisi statistica. La pulizia dei dati può includere
diverse attività, come:

-   Rimozione dei valori mancanti: si verifica la presenza di valori
    mancanti (NA) nel dataset e si sceglie come gestirli, ad esempio
    eliminandoli o sostituendoli con valori sostitutivi.

-   Correzione dei valori errati: si verifica la presenza di valori
    errati o anomali nel dataset e si sceglie come gestirli, ad esempio
    eliminandoli o sostituendoli con valori sostitutivi.

-   Trasformazione delle variabili: si verifica il tipo di dati per ogni
    variabile (ad esempio, numerico, carattere, data) e si effettua
    eventualmente la trasformazione.

-   Creazione di nuove variabili: si creano nuove variabili derivate
    dalle variabili esistenti, ad esempio calcolando il rapporto tra due
    variabili o creando una variabile binaria a partire da una variabile
    categoriale.

### Verifica della presenza di valori mancanti

Verifichiamo la presenza di NA nel dataset, dunque procediamo con il
comando **`sum(is.na(mpg))`** per contare il numero di valori mancanti.

```{r}
sum(is.na(mpg))

```

Non sono presenti valori nulli nel data frame. In caso contrario avremmo
potuto scegliere di sostituirli con la media o la moda, nel caso fossero
stati valori numerici.

Agli altri step non è dedicato nessun paragrafo in quanto non serve
affrontarli. Non ci sono valori errati, come sarà possibile osservare
nel summary mostrato successivamente nel report. Non c'è bisogno di
effettuare nessuna trasformazione di tipo in quanto ognuno è coerente e
non vediamo il bisogno di creare nuove variabili.

## Descrizione del dataset

Utilizziamo il comando **`str(mpg)`** per visualizzare una descrizione
delle variabili del dataset. Questo ci mostrerà il tipo di dati di ogni
variabile (ad esempio, numerico o carattere) e il numero di osservazioni
presenti per ogni variabile.

```{r}
str(mpg)

```

Il comando **`str()`** è utile per ottenere informazioni sulla struttura
del dataset e sulla tipologia di dati contenuti in ogni variabile. Ad
esempio, dalla descrizione delle variabili del dataset "mpg" mostrata
sopra, possiamo vedere che la variabile **`manufacturer`** è di tipo
carattere (**`chr`**), ovvero una stringa di testo, mentre la variabile
**`year`** è di tipo intero (**`int`**), ovvero un numero intero.

In R, il tipo numerico (**`numeric`**), come la variabile **`displ`**,
rappresenta i numeri con la virgola mobile, ovvero i numeri con
decimale. Ad esempio, 3.141592 è un numero numerico.

Il tipo intero (**`integer`**) rappresenta invece i numeri interi, lo
sono ad esempio **`year`** **`cyl`** ,ovvero i numeri senza decimale. Ad
esempio, 3 è un numero intero.

## Panoramica delle variabili

Utilizzando il comando **`summary(mpg)`** otteniamo una panoramica delle
statistiche descrittive per ogni variabile del dataset.

```{r}
summary(mpg)

```

La funzione **`summary()`** calcola automaticamente alcune statistiche
di base per ogni variabile, come ad esempio il valore minimo, il valore
massimo, la media, la mediana e la deviazione standard. Se la variabile
è di tipo numerico, verranno calcolate anche il quartile e il range
interquartile. Se la variabile è di tipo carattere o factor, verrà
conteggiato il numero di osservazioni per ogni livello o valore univoco
della variabile. La funzione **`summary()`** è utile per ottenere una
panoramica delle caratteristiche dei dati contenuti in un dataset. Ad
esempio, dall'output della funzione **`summary()`** per il dataset "mpg"
possiamo vedere il numero di osservazioni per ogni variabile (ad
esempio, "Length:234" indica che ci sono 234 osservazioni per ogni
variabile), il tipo di dati contenuti in ogni variabile (ad esempio,
"Class :character" indica che la variabile è di tipo carattere) e alcune
statistiche di base per ogni variabile (ad esempio, "Min. :1.600" indica
il valore minimo della variabile, "1st Qu.:2.400" indica il primo
quartile, "Median :3.300" indica la mediana e così via).

### Visualizzazione rapida dei grafici

Visualizziamo i grafici delle variabili numeriche del dataset mpg

```{r}
dfm <- mpg %>% 
  select_if(is.numeric)

```

Ora che abbiamo raccolto tutte le variabili di tipo numerico, guardiamo
il grafico ottenuto con pairs

```{r}
pairs(dfm)

```

Dal grafico notiamo che c'è una correlazione negativa tra le variabili
displ e cty e displ e hwy, ossia tra il volume dei cilindri
dell'automobile e il consumo di carburante in città ed in autostrada.
Quindi maggiore è il volume dei cilindri e minore è il consumo di
carburante. Una forte correlazione positiva vi è anche tra il consumo di
carburante in strada ed in autostrada.

## Tabelle di frequenza

Utilizziamo il comando **`table(mpg$variabile)`** per ottenere il
conteggio delle osservazioni per ogni categoria di una variabile. Ad
esempio, **`table(mpg$cyl)`** ti fornirà il conteggio delle osservazioni
per il numero di cilindri per ogni automobile.

La funzione **`table()`** è utile anche per ottenere una panoramica
delle caratteristiche di una variabile e per individuare eventuali
problemi o incongruenze nei dati. Ad esempio, se una variabile contiene
molti valori mancanti o valori anomali, questi verranno segnalati nella
tabella di frequenze.

### Manufacturer

La variabile manufacturer del dataset mpg rappresenta il produttore del
veicolo. Si tratta di una variabile categorica nominale, in quanto i
valori possibili sono limitati e non possono essere ordinati in base
alla loro posizione nella scala di valori. I valori possibili per la
variabile manufacturer sono 15 categorie diverse, ad esempio "audi",
"chevrolet", "dodge" e così via.

```{r}
df <- data.frame(Freq = c(table(mpg$manufacturer)), Perc_freq = c(table(mpg$manufacturer)/length(mpg$manufacturer)*100))
df

```

La variabile "Manufacturer" è di tipo carattere o factor e contiene
diversi nomi di produttori (ad esempio, "Ford", "Toyota", "Nissan"), la
tabella di frequenze mostrerà il numero di osservazioni per ogni
produttore.

### Model

La variabile model del dataset mpg rappresenta il modello del veicolo.
Si tratta di una variabile categoriale, in quanto i valori possibili
sono discreti e limitati.

```{r}
df <- data.frame(Freq = c(table(mpg$model)), Perc_freq = c(table(mpg$model)/length(mpg$model)*100))
df

```

Toyota tacome 4wd è il modello di veicolo più frequente in questo
dataset mentre il modello 4runner 4wd è il meno diffuso.

Del modello caravan 2wd ne sono presenti 11 veicoli dunque il 5% mentre
il modello a4 costituisce il 3% del set di dati.

### Displ

La variabile displ del dataset mpg rappresenta la cilindrata del motore
del veicolo, ovvero il volume delle camere di combustione, misurato in
pollici cubici (in). Si tratta di una variabile quantitativa continua.

```{r}
df <- data.frame(Freq =
c(table(mpg$displ)), Perc_freq = c(table(mpg$displ)/length(mpg$displ)*100))
df

```

Tutti i valori presenti nella tabella in alto rappresentano la
cilindrata del motore dei veicoli. 7 è il valore della cilindrata più
alto e ne è caratterizzato solo un veicolo ovvero solo 0.5%. La
cilindrata più bassa è 1.6 e 5 veicoli ne sono dotati ovvero il 2%
dell'intero set di dati.

### Year

Year indica l'anno di produzione dell'automobile. La variabile year del
dataset mpg rappresenta l'anno di produzione del veicolo. Si tratta di
una variabile quantitativa discreta, in quanto i valori possibili sono
limitati e non possono assumere valori intermedi.

```{r}
df <- data.frame(Freq =
c(table(mpg$year)), Perc_freq = c(table(mpg$year)/length(mpg$year)*100))
df

```

Dalla tabella di frequenza in alto possiamo notare che il 50% dei
veicoli è stato prodotto nel 1999 mentre l'altro 50% nel 2008.

### Cyl

La variabile cyl del dataset mpg rappresenta il numero di cilindri del
motore del veicolo. Si tratta di una variabile quantitativa discreta, in
quanto i valori possibili sono limitati e non possono assumere valori
intermedi.

```{r}
df <- data.frame(Freq =
c(table(mpg$cyl)), Perc_freq = c(table(mpg$cyl)/length(mpg$cyl)*100))
df

```

I valori elencati sono il numero di cilindri del motore dei veicoli,
possiamo notare che il 35% dei veicoli ha un numero di cilindri pari a
4, 70 auto circa il 30% ha un motore a 8 cilindri, 4 veicoli sono dotati
di un motore a 5 cilindri ed infine il 34% delle auto ha un motore a 6
cilindri.

### Trans

La variabile trans del dataset mpg rappresenta il tipo di trasmissione
del veicolo. Si tratta di una variabile categorica ordinale, in quanto i
valori possibili sono limitati e possono essere ordinati in base alla
loro posizione nella scala di valori.

```{r}
df <- data.frame(Freq =
c(table(mpg$trans)), Perc_freq = c(table(mpg$trans)/length(mpg$trans)*100))
df

```

I valori presenti in questa tabella rappresentano il tipo di
trasmissione dei veicoli: 83 veicoli ovvero 36% del dataset hanno il
tipo di trasmissione auto(l4), circa il 25% sono caratterizzati dalla
trasmissione manual(m5), 39 auto invece dalla trasmissione auto(l5).

### Drv

La variabile drv del dataset mpg rappresenta il tipo di trazione del
veicolo. Si tratta di una variabile categorica nominale, in quanto i
valori possibili sono limitati e non possono essere ordinati in base
alla loro posizione nella scala di valori. I valori possibili per la
variabile drv sono "f", "r" e "4", che indicano rispettivamente trazione
anteriore, trazione posteriore e trazione integrale.

```{r}
 df <- data.frame(Freq =
c(table(mpg$drv)), Perc_freq = c(table(mpg$drv)/length(mpg$drv)*100))
df

```

103 auto dunque il 44% possiedono la trazione integrale, il 45% dunque
106 auto hanno la trazione anteriore infine 25 veicoli il 10% sono
caratterizzati dalla trazione posteriore.

### Cty

La variabile cty del dataset mpg rappresenta il numero di miglia per
gallone che un veicolo può percorrere in città. Si tratta di una
variabile quantitativa continua, in quanto i valori possibili sono
numeri reali che possono assumere valori intermedi.

```{r}
df <- data.frame(Freq =
c(table(mpg$cty)), Perc_freq = c(table(mpg$cty)/length(mpg$cty)*100))
df

```

35 è il numero massimo di miglia per gallone che 1 auto del nostro
dataset può percorrere in città, il numero minimo di miglia per gallone
che 5 auto (2%) del nostro set di dati possono fare in città è 9.

### Hwy

La variabile hwy del dataset mpg rappresenta il numero di miglia per
gallone che un veicolo può percorrere su strada. Si tratta di una
variabile quantitativa continua, in quanto i valori possibili sono
numeri reali che possono assumere valori intermedi.

```{r}
df <- data.frame(Freq =
c(table(mpg$hwy)), Perc_freq = c(table(mpg$hwy)/length(mpg$hwy)*100))
df
```

2 auto del dataset dunque l'1% riescono a percorrere 44 miglia per
gallone su strada, il 2% ovvero 12 auto coprono solo 12 miglia per
gallone su strada e cosi via.

### Fl

La variabile fl del dataset mpg rappresenta il tipo di carburante
utilizzato dal veicolo. Si tratta di una variabile categorica nominale,
in quanto i valori possibili sono limitati e non possono essere ordinati
in base alla loro posizione nella scala di valori. I valori possibili
per la variabile fl sono "p", "c", "e", "r" e "d", che indicano
rispettivamente: carburante premium, carburante normale (etanolo 85),
elettricità, carburante regolare e diesel.

```{r}
df <- data.frame(Freq =
c(table(mpg$fl)), Perc_freq = c(table(mpg$fl)/length(mpg$fl)*100)) 
df

```

Dalla tabella di frequenza possiamo notare che 1 auto usa il carburante
normale per viaggiare, il gasolio premium lo usano il 22% circa di
veicoli dunque 52 auto, il carburante regolare è quello più comune
infatti 168 auto ovvero 168 veicoli ne fanno uso infine 8 auto si
riforniscono con l'elettricità e 5 veicoli con il diesel.

### Class

La variabile class del dataset mpg rappresenta la classe di veicolo a
cui appartiene il veicolo. Si tratta di una variabile categorica
nominale, in quanto i valori possibili sono limitati e non possono
essere ordinati in base alla loro posizione nella scala di valori. I
valori possibili per la variabile class sono 19 categorie diverse, ad
esempio "suv", "pickup", "minivan" e così via.

```{r}
df <- data.frame(Freq =
c(table(mpg$class)), Perc_freq = c(table(mpg$class)/length(mpg$class)*100))
df

```

La classe di veicolo più frequente è suv infatti di questa classe sono
presenti 62 auto dunque il 25%, 5 veicoli circa il 2% appartiene alla
classe di veicolo 2seater e così via.

## Visualizzazione dei dati

Visualizzare i dati attraverso grafici serve a diverse finalità:

1.  Facilitare la comprensione dei dati: i grafici possono aiutare a
    rappresentare in modo visivo i dati e a renderli più facili da
    comprendere. Ad esempio, un grafico a barre può mostrare facilmente
    le frequenze di una variabile categoriale, mentre un grafico a linee
    può mostrare l'evoluzione di una variabile nel tempo.

2.  Individuare pattern e tendenze: i grafici possono aiutare a
    individuare pattern e tendenze nei dati, che altrimenti potrebbero
    essere difficili da rilevare dall'analisi dei dati in forma
    tabellare.

3.  Fare confronti e raffronti: i grafici possono consentire di fare
    confronti e raffronti tra diverse categorie o gruppi di dati, ad
    esempio confrontando le frequenze di diverse variabili.

4.  Comunicare i risultati: i grafici possono essere utilizzati per
    comunicare i risultati di un'analisi a un pubblico più ampio, anche
    a persone che non sono esperte di statistica o di analisi dei dati.
    Ad esempio, un grafico può essere incluso in un report o in una
    presentazione, come in questo caso, per illustrare in modo chiaro e
    conciso i risultati di un'analisi.

### Variabile manufacturer

Per visualizzare la variabile "manufacturer" del dataset "mpg" con
ggplot2, utilizziamo un grafico a barre e un grafico a torta. Entrambi
questi grafici sono adatti per visualizzare le frequenze di una
variabile di tipo carattere o factor, come la variabile "manufacturer".

#### Grafico a Barre

Il grafico a barre è un tipo di grafico utilizzato per visualizzare le
frequenze di una variabile di tipo carattere o factor. In particolare,
ogni barra del grafico rappresenta il numero di osservazioni per un
determinato livello o valore univoco della variabile.

```{r message=FALSE, warning=FALSE}
p1 <- ggplot(mpg, aes(x = manufacturer)) +
     geom_bar(color = "black", fill = "white") + theme(axis.text.x = element_text(angle = 90)) + ylab("Manufacturer")

p1 <- p1 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#ffffff', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p1
```

Il comando ha prodotto un grafico a barre che visualizza il numero di
osservazioni per ogni produttore di auto presente nella variabile
"manufacturer".

Il grafico a barre è utile per ottenere una panoramica delle
caratteristiche di una variabile e per individuare eventuali tendenze o
pattern nei dati. Ad esempio, se un produttore di auto è presente in
molti più casi rispetto agli altri, questo potrebbe indicare che è più
popolare o diffuso.

#### Grafico a Torta

Il grafico a torta (o grafico a settori) è un tipo di grafico utilizzato
per visualizzare le frequenze di una variabile di tipo carattere o
factor. In particolare, ogni settore della torta rappresenta la
percentuale di osservazioni per un determinato livello o valore univoco
della variabile.

```{r}
Manufacturer <- factor(mpg$manufacturer, levels = names(sort(table(mpg$manufacturer))))
p2 <- ggplot(mpg, aes(x = "", y = manufacturer, fill = Manufacturer)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar("y") + theme_void()

p2 <- p2 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p2

```

Il grafico a torta mostra la distribuzione delle osservazioni per ogni
produttore di auto presente nella variabile 'manufacturer' del dataset
'mpg'.

ll grafico mostra che il produttore 'volkswagen' è presente in circa il
40% delle osservazioni, seguito da 'toyota' con il 50% e così via\...

### Variabile model

Anche in questo caso essendo la variabile categoriale procediamo con la
rappresentazione attraverso un grafico a barre, mentre non verrà
mostrato il grafico a torta in quanto è irrilevante, la presenza di così
tante categorie non permetterebbe di distinguere l'una dall'altra.

#### Grafico a barre

```{r}
p3 <- ggplot(mpg, aes(x = model, fill = Manufacturer)) +
  geom_bar(position = "dodge")+ theme(axis.text.x = element_text(angle = 90))+ ylab("Manufacturer")

p3 <- p3 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#ffffff', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p3


```

Il grafico a barre della variabile "model" condizionato a "manufacturer"
mostra la distribuzione delle frequenze dei modelli di auto per ogni
produttore. Ad esempio, possiamo vedere quanti modelli di auto di ogni
produttore sono presenti nel dataset "mpg". Il grafico può essere utile
per ottenere una panoramica della presenza di ogni produttore
all'interno del dataset e per comparare le frequenze dei modelli di auto
tra i diversi produttori. Con questo grafico sappiamo ogni modello a
quale casa produttrice appartiene e conosciamo anche quanti di quei
modelli sono presenti nel dataset.

### Variabile displ

La variabile displ rappresenta il volume dei cilindri dell'automobile,
in litri. Per visualizzare i dati della variabile "displ" del dataset
"mpg", utilizziamo un istogramma.

#### Istogramma

Gli istogrammi sono formati da bins, ossia le barre verticali che
dividono l'asse delle ascisse in intervalli di valori. Ogni barra
rappresenta un bin, ovvero un intervallo di valori, e l'altezza della
barra indica il numero di osservazioni che cadono all'interno di
quell'intervallo.

Per scegliere il numero ottimale di bins abbiamo utilizzato la regola di
Sturges, questa ci suggerisce di utilizzare il numero di bins pari a
**`log2(n) + 1`**, dove **`n`** è il numero di osservazioni.

```{r}
n_bins_sturges <- function(x) {
  log2(length(x)) + 1
}
```

L'istogramma è un grafico che mostra la distribuzione delle frequenze di
una variabile numerica. È utile per ottenere una panoramica delle
caratteristiche della variabile, come la forma della distribuzione, il
valore medio ecc.

```{r message=FALSE, warning=FALSE}
p4 <- ggplot(mpg, aes(x = displ)) + geom_histogram(bins = 30, aes(y = ..density..), color = "black", fill = "white") + 
  geom_freqpoly(aes(y = ..density..), color = "red", size = 1) + labs(title = "Distribuzione dei valori di displ") 


p4 <- p4 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p4
```

L'istogramma della variabile "displ" mostra la distribuzione dei valori
della variabile. Ad esempio, possiamo vedere qual è la frequenza di ogni
valore di "displ" all'interno del dataset "mpg". Il grafico visualizza i
valori di "displ" come valori in ascissa e le frequenze come valori in
ordinata.

La curva di frequenza mostra la frequenza cumulativa dei valori di
"displ", ossia la somma delle frequenze di una variabile fino a un
determinato valore.

Si può notare che la maggior parte dei valori di "displ" sono compresi
tra 1 e 4, con un picco intorno a 2. Ciò indica che la distribuzione dei
valori è sbilanciata a sinistra, con una maggiore concentrazione di
valori a sinistra della media.

#### Grafico a barre

Vogliamo confrontare i valori della variabile "disp" tra le diverse
categorie della variabile "class". Per farlo utilizziamo un grafico a
barre con i valori di "disp" come valori in ascissa e le categorie di
"class" come valori in ordinata:

```{r}
macchina <- factor(mpg$class, ordered = T)
p5 <- ggplot(mpg, aes(x = macchina, y = displ)) +
  geom_bar(stat = "identity", fill = "white") + ylab("displ") + xlab("Class")


p5 <- p5 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p5
```

Dal grafico possiamo osservare sulle ascisse i tipi di veicoli.

#### Grafico a dispersione

Questo grafico mostra la relazione tra due variabili numeriche.
Utilizziamo il grafico a dispersione per visualizzare come i valori di
"displ" sono correlati ai valori di un'altra variabile numerica, come
"cty" (l consumo di carburante in città, in miglia per gallone).

```{r}
p6 <- ggplot(mpg, aes(x = displ, y = cty)) +
  geom_point()

p6 <- p6 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#fff68f', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p6
```

Sull'asse delle ascisse ci sono le cilindrate del motore, ossia il
numero di camere di combustione, sull'asse delle ordinate c'è il consumo
di carburante in città, in miglia per gallone

Dal grafico vediamo che all'aumentare del numero di cilindri diminuisce
il consumo di carburante in città.

#### Funzione di distribuzione empirica discreta

La funzione di distribuzione empirica $F(x)$ è definita per ogni $x$
reale ed è una funzione a gradini in cui ogni gradino indica quale
proporzione di dati presenta un valore minore o uguale di quello
indicato sull'asse delle ascisse.

La funzione di distribuzione empirica $F(x)$ gode delle seguenti
proprietà:

\- è una funzione non decrescente;

\- la funzione assume il valore a sinistra in corrispondenza ad ogni
punto di salto;

\- la funzione vale 0 per ogni valore minore dell'osservazione minima e
vale 1 per ogni valore maggiore o uguale dell'osservazione massima.

```{r}
# Frequenze relative cumulative
round(cumsum(table(mpg$displ)/length(mpg$displ)),3)

```

La funzione $ecdf()$ (empirical cumulative distribution function)
permette di disegnare il grafico della funzione di distribuzione
empirica per variabili quantitative discrete.

```{r}
plot(ecdf(mpg$displ),main=" Funzione di distribuzione empirica discreta ",verticals =FALSE ,col ="red ")

```

Se si utilizza l'opzione $verticals = TRUE$ i segmenti sono uniti da
segmenti verticali.

### Variabile Year

Year indica l'anno di produzione dell'automobile. Innanzitutto
applichiamo la funzione **`summary()`** per ottenere un riassunto delle
statistiche di base per la variabile **`Year`**, come ad esempio la
media, la mediana, il minimo e il massimo.

```{r}
summary(mpg$year)

```

L'auto più vecchia del dataset è del 1999, mentre la più recente è del
2008. Questo ci fa capire che le auto prese in esame sono modelli molto
vecchi rispetto a quelli attuali.

#### Istogramma

Nel chunk successivo applichiamo la funzione **`geom_histogram`**,
l'equivalente di **`hist()`**, per creare un istogramma della variabile
**`Year`**. L'istogramma ci aiuterà a visualizzare la distribuzione dei
valori della variabile e a identificare eventuali outlier.

```{r}
p7 <- ggplot(mpg, aes(x = year)) + geom_histogram(bins = 30, aes(y = ..density..), color = "black", fill = "white")
p7 <- p7 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#fff68f', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p7
```

Da questo grafico capiamo che gli anni di produzione sono solo 2, il
1999 e il 2008. Quindi sono presenti due generazioni di veicoli, alcuni
prodotti alla fine del 20esimo secolo e altri all'inizio del 21 secolo,
discostanti da loro di 10 anni.

#### Boxplot

Con la funzione **`boxplot()`** creiamo un grafico a scatola a baffi
della variabile **`Year`**.

```{r}
p8 <- ggplot(mpg, aes(x = year)) + geom_boxplot() + coord_flip()
p8 <- p8 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#fff68f', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p8
```

Il boxplot in questo caso appare anomalo, perché non ha i baffi, questo
perché il primo quartile corrisponde al minimo e il terzo quartile
corrisponde al massimo.

#### Boxplot ad intaglio

Possiamo utilizzare anche i boxplot ad intaglio i quali sono una
rappresentazione grafica dei boxplot ma con l'aggiunta dell'intervallo
di confidenza:

```{r}
p8 <- ggplot(mpg, aes(x = year)) + geom_boxplot(notch = TRUE) + coord_flip()
p8 <- p8 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#fff68f', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p8
```

```{r}
IQR <- quantile(mpg$year,0.75) - quantile(mpg$year, 0.25)
M1 <- quantile(mpg$year,0.5) - 1.57 *IQR/sqrt(length(mpg$year))
M2 <- quantile(mpg$year,0.5) + 1.57 *IQR/sqrt(length(mpg$year))
c(M1 ,M2)

```

Il numero 1.57 è dovuto al rapporto $(1.25 · 1.7)/1.35$ che appare
nell'approssimazione della formula dell'intervallo di confidenza(che
vedremo in seguito); quindi, con un grado di fiducia del 95%
l'intervallo di confidenza approssimato per la mediana è
$(2002.576, 2004.424)$.

### Variabile Cyl

La variabile **`cyl`** del dataset **`mpg`** rappresenta il numero di
cilindri del motore dei veicoli. Si tratta di una variabile categoriale,
in quanto i valori possibili sono discreti e limitati.

#### Barplot

Nel seguente chunk abbiamo creato un grafico a barre per visualizzare la
distribuzione dei valori.

```{r}
p9 <- ggplot(data = mpg, mapping = aes(cyl)) + geom_bar(stat = "count", fill= "white", col = "black") + ggtitle("Variabile cyl") + ylab("Cilindri")

p9 <- p9 + theme(panel.background = element_rect(fill = '#f0e2a8', color = "#9a8262"), panel.grid.major = element_line(color = '#ffffff', linetype="longdash"),panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash"))

p9
```

Nel grafico, "cyl" sarà mostrata sull'asse delle ascisse e il numero di
osservazioni per ogni valore sarà mostrato sull'asse delle ordinate.

Il grafico a barre mostra che ci sono molte più macchine con un numero
di cilindri pari a 4 rispetto a vetture con un numero di cilindri pari a
5 o 8.

#### Grafico a torta

Utilizziamo un grafico a torta per mostrare le frequenze di ogni valore
di "cyl" come percentuali dell'intero dataset.

Per avere un grafico a torta corretto, bisogna prima trasformare la
variabile cyl in un fattore e riordina i valori in base alla frequenza,

```{r}
Cilindri <- factor(mpg$cyl, levels = names(sort(table(mpg$cyl))))
```

In questo modo, i valori di "Cilindri" verranno ordinati in base alla
frequenza, dal valore più frequente al meno frequente

```{r}

p10 <- ggplot(mpg, aes(x = "", y = Cilindri, fill = Cilindri)) +
  geom_bar(width = 1,stat = "identity") +
  coord_polar("y") + theme_void()

p10 <- p10 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p10

```

Il grafico a torta ci da una conferma di quello che avevamo già visto
nel grafico a barre, la presenza di veicoli a 4 cilindri è superiore
alle altre. In sostanza il dataset è formato quasi interamente da
veicoli a 4 e 6 cilindri.

### Variabile trans

La variabile **`trans`** del dataset **`mpg`** rappresenta il tipo di
trasmissione dei veicoli. Si tratta di una variabile categoriale, in
quanto i valori possibili sono discreti e limitati.

#### Barplot

```{r}
p11 <- ggplot(mpg, mapping = aes(trans)) +
  geom_bar(fill = "white", col = "black") + ylab("Trasmissione")

p11 <- p11 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p11

```

Dall'istogramma possiamo notare che ci sono molti veicoli con il tipo di
trasmissione *auto(l4)* e il tipo di trasmissione *manual(m5)* .

#### Boxplot

```{r}
p12 <- ggplot(mpg, aes(x = trans, y = displ)) +
  geom_boxplot()

p12 <- p12 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p12
```

Il boxplot è un grafico utile per visualizzare la distribuzione di una
variabile continua stratificata per una variabile discreta, poiché
permette di individuare facilmente le differenze tra le distribuzioni
delle diverse categorie. Ad esempio, in questo caso, il grafico mostra
come la distribuzione dei valori della variabile **`displ`** cambi in
base al tipo di trasmissione del veicolo. Possiamo notare ad esempio che
la mediana dei valori della variabile **`displ`** per il tipo di
trasmissione "automatic" è leggermente più alta rispetto al tipo di
trasmissione "manual". Oppure, che ci sono più outliers per il tipo di
trasmissione "automatic" rispetto al tipo di trasmissione "manual".

### Variabile Drv

La variabile Drv rappresenta il tipo di trazione dell'automobile
(anteriore, posteriore o integrale).

#### Barplot

```{r}
drive <- factor(mpg$drv, levels = c("4", "f", "r"), labels = c("trazione integrale", "trazione anteriore", "trazione posteriore"))
p13 <- ggplot(mapping = aes(drive)) + 
  geom_bar(fill = "white", col = "black") + ylab("Trazione")

p13 <- p13 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p13

```

La maggior parte dei veicoli possiede la trazione integrale e la
trazione anteriore, sono pochi i veicoli con la trazione posteriore.

#### Scatterplot

```{r}
p14 <- ggplot(mpg, aes(x = drive, y = displ)) +
  geom_point()

p14 <- p14 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p14
```

Dallo scatterplot possiamo osservare che i veicoli con la trazione
integrale, possono avere qualsiasi volume dei cilindri (in litri). I
veicoli con la trazione anteriore invece possiedono la cilindrata del
motore bassa a differenza delle auto con la trazione posteriore che sono
caratterizzate da una cilindrata alta.

Giungiamo alla medesima conclusione osservando il boxplot in basso.

#### Boxplot

```{r}
p15 <- ggplot(mpg, aes(x = drv, y = displ)) +
  geom_boxplot() + coord_flip()

p15 <- p15 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p15
```

La centralità delle scatole, espressa dalla mediana vediamo che non è
propriamente al centro, ciò sta a significare che non c'è simmetria nei
dati, piuttosto la distribuzione è asimmetrica, come nel caso del primo
boxplot che è fortemente asimmetrica a sinistra. Dall'ultimo boxplot
notiamo dalla lunghezza dei baffi che c'è molta dispersione nei dati.
Mentre nel secondo boxplot vediamo che c'è un outliers, ossia un valore
anomalo che va molto al di fuori dei baffi.

### Variabile Cty

La variabile Cty rappresenta il consumo di carburante in città, in
miglia per gallone.

#### Istogramma e kernel density

```{r}
p16 <- ggplot(data = mpg, mapping = aes(cty,..density..)) + 
  geom_histogram(bins = 30, fill = "white", col = "black")+
  geom_density()

p16 <- p16 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p16
```

Dall'istogramma possiamo osservare come si distribuisce la variabile, è
evidente che la maggior parte dei veicoli percorrono tra i 10 e i 20
miglia con un gallone.

### Indici di sintesi

Alcuni indici di sintesi, detti anche statistiche, utili a descrivere
dei dati numerici, sono media, mediana, moda, varianza, deviazione
standard e coefficiente di variazione. La media, la mediana e la moda
sono misure di centralità, mentre la varianza e la deviazione standard
misurano la dispersione dei dati.

#### Media campionaria

La media campionaria è la media aritmetica di questi valori.

Definizione 4.1: Si definisce media campionaria e si denota con $x$, la
quantità:

$$\overline x = \frac1n \sum^n_{i=1}x_i$$

La media campionaria è una media pesata dei valori distinti assunti dai
dati. Ogni valore distinto usa come peso la sua frequenza relativa,
ovvero la frazione dei dati uguale a tale valore numerico.

```{r}
mean(mpg$cty)
```

La media campionaria utilizza tutti i dati ed è influenzata in maniera
sensibile da valori eccezionalmente alti o bassi.

#### Mediana Campionaria

Assegnato un insieme di dati di ampiezza $n$, lo si ordini in ordine
crescente (dal valore più piccolo al valore più grande). Se n è dispari,
si definisce mediana campionaria il valore che è in posizione
$(n +1)/2$, mentre se $n$ è pari la mediana campionaria è invece
definita come la media aritmetica dei valori che occupano le posizioni
$n/2$ e $n/2+ 1$.

```{r}
median(mpg$cty)

```

La mediana campionaria dipende solo da uno o da due valori centrali dei
dati e non risente dei valori estremi. Inoltre, l'uso della mediana come
indice per descrivere le caratteristiche dei dati ha lo svantaggio di
dover prima riordinare i dati in ordine crescente, il che non è
richiesto per il calcolo della media.

#### Moda campionaria

La moda campionaria di un insieme di dati, se esiste, è la modalità a
cui è associata la frequenza (assoluta o relativa) più elevata. Se
esistono più modalità con frequenza massima, ciascuna di esse è detto
valore modale.

Non esiste invece in R una funzione per estrarre la moda o la classe
modale di una distribuzione di dati poiché è facilmente ricavabile
osservando il grafico delle frequenze assolute o l'istogramma delle
frequenze relative.

#### Quantili, percentili, decili e quartili

-   I *quartili,* come dice la parola stessa, si ottengono dividendo
    l'insieme di dati ordinati in 4 parti uguali. (quantili di ordine
    1/4, 1/2, 3/4)

-   I *percentili*, invece, dividendo la distribuzione in 100 parti
    (quantili di ordine 1/100)

-   I *decili,* infine, dividono la distribuzione in 10 parti uguali
    (quantili di ordine 1/10).

#### Varianza, deviazione standard e coefficiente di variazione

Assegnato un insieme di dati numerici $x_1, x_2, . . . , x_n$, si
definisce varianza campionaria, e si denota con $s^2$, la quantità:

$$s^2 = \frac {1}{n-1} \sum^n_{i=1}(x_i - \overline x)^2$$

con $$(n=2,3,...)$$

```{r}
var(mpg$cty)

```

dove $$\overline x$$ denota la media campionaria dei dati. Inoltre, si
definisce deviazione standard campionaria la radice quadrata della
varianza campionaria.

```{r}
sd(mpg$cty)

```

Varianza campionaria e deviazione standard campionaria sono detti indici
di dispersione o indici di variabilità poiché misurano la dispersione
dei dati intorno alla media.

I valori della varianza campionaria e della deviazione standard
campionaria dipendono dall'unità di misura dei dati.

#### Coefficiente di variazione

Per confrontare le variazioni esistenti tra diversi campioni di dati è
utile introdurre coefficiente di variazione.

Assegnato un insieme di dati numerici $x1, x2, . . . , xn$, si definisce
coefficiente di variazione il rapporto tra la deviazione standard
campionaria e il modulo della media campionaria, ossia:

$$CV=\frac {s}{|\overline x|}$$

Si nota che il coefficiente di variazione è un numero puro, ossia è un
indice indice *adimensionale* che non dipende dall'unità di misura
utilizzata.

Il coefficiente di variazione è utilizzato quando è necessario
confrontare tra loro le dispersioni (variabiltà) di insiemi di dati
espressi in differenti unità di misura.

In R si implementa nel seguente modo:

```{r}
cv <- function(x){
+ sd(x)/abs(mean(x))}

cv(mpg$cty)

```

#### Momenti campionari

Assegnato un insieme di dati numerici $x1, x2, . . . , xn$, si definisce
momento campionario di ordine j e si denota con $M_j$ la quantità:

$$M_j = \frac {1}{n} \sum^n_{i=1} x^j_i$$

con $$(j=1,2,...)$$

#### Momento centrato

Assegnato un insieme di dati numerici $x1, x2, . . . , xn$, si definisce
momento campionario centrato intorno alla media di ordine j e si denota
con $m_j$ la quantità:

$$
m_j = \sum^n_{i=1} (x_i-
\overline x)^j
$$

#### Scatterplot

```{r}
p17 <- ggplot(data = mpg, mapping = aes(x = cty, y = displ)) +
  geom_point()

p17 <- p17 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p17

```

Le variabili displ (volume dei cilindri dell'automobile, in litri) e cty
(consumo di carburante in città, in miglia per gallone) sono correlate
negativamente, infatti all'aumentare delle miglia che il veicolo può
percorrere con un gallone diminuisce la cilindrata del motore dell'auto.

```{r}
p18 <- ggplot(mpg, aes(x = cyl, y = cty)) +
  geom_point()

p18 <- p18 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p18
```

Osservando lo scatter plot possiamo affermare che le auto con un numero
di cilindri pari a *4 e 5* riescono a percorrere più miglia con un
gallone in città mentre le auto con *6* e *8* cilindri riescono a
percorrere meno miglia per gallone in zona urbana.

#### Istogramma

Utilizziamo la funzione **`cut()`** per raggruppare i dati e creare un
istogramma con degli intervalli scelti.

```{r}
fcut <- table (cut ( mpg$cty, breaks = c(12,14,17,20,35) ))
fcut
```

Gli intervalli sono scelti in modo da essere abbastanza equi.

```{r}
barplot(fcut, col = rainbow(4), xlab = "miglia per gallone", main = "Grafico miglia per gallone", ylab = "n.osservazioni")
```

### Variabile Hwy

La variabile hwy del dataset mpg rappresenta il numero di miglia per
gallone che un veicolo può percorrere su strada.

Usando le funzioni di visualizzazione come **`ggplot()`** del pacchetto
**`ggplot2`** è possibile creare grafici che mostrino le relazioni tra
le variabili del dataset o la distribuzione di singole variabili. Ad
esempio, abbiamo creato un istogramma per visualizzare i consumi di
carburante **`hwy`** dei veicoli del dataset.

#### Istogramma

```{r}
p19 <- ggplot(data = mpg, mapping = aes(hwy)) +
  geom_histogram(bins = 30, fill = "white", col = "black") 

p19 <- p19 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p19

```

#### Kernel density plot

Il grafico kernel density plot è un grafico che mostra l'approssimazione
della distribuzione dei valori di una variabile continuamente misurata.
È ottenuto tramite l'utilizzo di una tecnica di smoothing nota come
"kernel density estimation", che consiste nell'aggiungere una curva di
densità di kernel sopra ogni osservazione. La curva di densità di kernel
è una funzione continua che rappresenta la distribuzione di probabilità
dei valori di una variabile.

Il grafico kernel density plot è spesso utilizzato per esplorare la
distribuzione di una variabile e per confrontare le distribuzioni di
diverse variabili. Ad esempio, abbiamo utilizzato il grafico kernel
density plot per confrontare la distribuzione dei valori della variabile
**`hwy`**.

```{r}
p20 <- ggplot(data = mpg, mapping = aes(hwy)) +
  geom_density(fill = "white", col = "black")

p20 <- p20 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p20

```

La maggior parte dei veicoli presenti in questo dataset percorrono su
strada tra i 20 e i 30 miglia con un gallone.

Introduciamo a tal proposito le definizioni di simmetria (skewness) e di
curtosi di una distribuzione:

**Definizione del coefficiente di simmetria**: Assegnato un insieme di
dati numerici $x_1, x_2,…x_n$ si definisce skewness campionaria il
valore:

$$\gamma = \frac{m_3}{m_2^{3/2}}$$

si nota che:

-   $\gamma = 0$ se la distribuzione di frequenze è simmetrica

-   $\gamma > 0$ se la distribuzione di frequenze è asimmetria positiva
    (ossia ha la coda di destra più allungata)

-    $\gamma < 0$ se la distribuzione di frequenze è asimmetria negativa
    (ossia ha la coda di sinistra più allungata).

Si nota che $\gamma$ è un indice adimensionale, ossia è indipendente
dall'unità di misura dei dati.

Il calcolo della skewness campionaria può essere così implementato in R:

```{r}
skw <- function (x){
n <-length (x)
m2 <-(n -1) *var (x)/n
m3 <- (sum ( (x-mean(x))^3) )/n
m3/(m2 ^1.5)
 }

```

```{r}
skw(mpg$hwy)

```

il vettore presenta un'asimmetria positiva infatti ha la coda di destra
più allungata.

**Definizione della curtosi campionaria**

Un indice che permette di misurare la densità dei dati intorno alla
media è la curtosi campionaria;

Assegnato un insieme di dati numerici $x_1, x_2, . . . , x_n$, si
definisce curtosi campionaria il valore:

$$\gamma_2 = \beta_2-3$$

dove $\beta_2=\frac{m_4}{m_2^2}$ è l'indice di Pearson che è un indice
adimensionale, ossia è indipendente dall'unità di misura dei dati.

Gli indici $γ_2$ e $β_2$ permettono di confrontare la distribuzione di
frequenze dei dati con una densità di probabilità normale standard,
caratterizzata da $β_2 = 3$ e indice di curtosi $γ_2 = 0$. Se risulta:

-   $β_2 < 3 \ (γ_2 < 0)$: la distribuzione di frequenze si definisce
    platicurtica, ossia la distribuzione di frequenze è più piatta di
    una normale;

-   $β_2 > 3 \  (γ_2 > 0)$: la distribuzione di frequenze si definisce
    leptocurtica, ossia la distribuzione di frequenze è più piccata di
    una normale;

-   $β_2 = 3 \ (γ_2 = 0)$: la distribuzione di frequenze si definisce
    normocurtica (mesocurtica), ossia piatta come una normale.

Il calcolo della curtosi campionaria ha significato soltanto per
distribuzioni di frequenze unimodali, dato che tale indice è confrontato
con quello di una normale standard.

Quindi nel nostro caso non ha senso calcolarlo dato che la nostra
distribuzione è bimodale

#### Grafico a dispersione

```{r}
p21 <- ggplot(data = mpg, mapping = aes(x = hwy, y = displ)) +
  geom_point()

p21 <- p21 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p21

```

Dallo scatterplot è evidente che la variabile *hwy* (consumo di
carburante in autostrada, in miglia per gallone) è correlata
negativamente con la variabile *displ* (cilindrata del motore,ovvero il
volume delle camere di combustione, misurato in pollici cubici (in)),
possiamo affermare infatti che all'aumentare delle miglia che il veicolo
può percorrere su strada, con un gallone, diminuisce la cilindrata del
motore, dunque più alta è la cilindrata e minori sono le miglia che il
veicolo percorrerà con un gallone su strada.

#### Funzione di distribuzione empirica continua

Per fenomeni quantitativi continui occorre considerare la funzione di
distribuzione empirica continua, ossia una funzione di distribuzione
empirica strutturata in classi.

Come primo step creiamo le classi:

```{r}

# Frequenza relativa dei voti
freqrel <- table(mpg$hwy)/length(mpg$hwy)

# Lunghezza del vettore frequenza
m <- length(freqrel)

# Creazione delle classi
classi <-c(15 ,18 ,21 ,24 ,27, 30, 33, 36, 39, 44)

# Frequenze relative delle classi
freqClassi <- table(cut(mpg$hwy, breaks = classi, right = FALSE))/length(mpg$hwy)

# Frequenze cumulata
Fcum <- cumsum(freqClassi)
Fcum[9] <- 1

```

Per ottenere tali frequenze abbiamo utlizzato la funzione $cut()$ con
l'opzione $right = FALSE$ che consente di costruire classi con
intervalli chiusi a sinistra invece che a destra ed anche la funzione
$cumsum()$ che permette di ottenere le frequenze cumulative.

Ricordiamo che in R la funzione $cut()$ trasforma dati numerici in dati
qualitativi mediante la loro collocazione in opportune classi sulla base
di quanto specificato nel parametro breaks.

Vogliamo ora scrivere delle linee di codice in R che consentono di
ottenere il grafico della funzione di distribuzione empirica continua
introducendo due classi fittizie $C_0 = (12, 15)$ e $C_5 = (44, 47)$ che
ci serviranno per tracciare la linea $y = 0$ nell'intervallo *[12, 15)*
e la linea $y = 1$ nell'intervallo *[44, 47)* nel grafico della funzione
di distribuzione empirica continua.

```{r}
ascisse <-c(12, 15 ,18 ,21 ,24 ,27, 30, 33, 36, 39, 44, 47)
ordinate <-c(0, 0, Fcum [1:9] ,1)
plot(ascisse , ordinate , type = "b", axes = FALSE , main = "Funzione di distribuzione empirica continua ", col =" red ",ylim=c(0 ,1) ,xlab="x",ylab="F(x)")
axis(1, ascisse )
axis(2, format (Fcum , digits = 2))
box()
```

Grafico della funzione di distribuzione empirica continua del vettore
*hwy* utilizzando le classi:

    [15,18)  [18,21)  [21,24)  [24,27)  [27,30)  [30,33) [33,36)  [36,39)  [39,44) 

### Variabile Fl

La variabile fl del dataset mpg rappresenta il tipo di carburante
utilizzato dal veicolo. I valori possibili per la variabile fl sono "p",
"c", "e", "r" e "d", che indicano rispettivamente: carburante premium,
carburante normale (etanolo 85), elettricità, carburante regolare e
diesel.

#### Grafico a barre

```{r}
fuel <- factor(mpg$fl, levels = c("c","d","e","p","r"), labels = c("Normale gasoline", "Diesel", "Elettricity","Premium gasoline", "Regular gasoline")) 

p22 <- ggplot(data = mpg, mapping = aes(x = fuel)) +
  geom_bar(col = "black", fill = "white") + ylab("Fuel")

p22 <- p22 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p22

```

Possiamo notare che la maggiore parte delle auto presenti nel set di
riferimento, circa il 72%, usa il gasolio regolare per viaggiare, il 22%
si rifornisce con il carburante premium ed il restante 6% delle auto con
gli altri combustibili: elettricità, diesel o carburante normale.

#### Grafico frequenze relative cumulative

Le frequenze assolute cumulative sono il numero di osservazioni di una
variabile che sono inferiori o uguali a un determinato valore In R,
utilizziamo la funzione **`cumsum()`** per calcolare le frequenze
assolute cumulative di una variabile.

```{r}
fac <- cumsum(table(mpg$fl)/length(mpg$fl))
names(fac) <- c("Normal_gasoline", "Diesel", "Elettricity", "Premium_Gasoline", "Regular gas")

plot(fac, type = "s", main = "FRC Carburante", ylim = c(-0.5,1.3), xlab= "Tipo di carburante")
```

Il grafico a gradini mostra il numero di automobili con trasmissione
"fl" che sono presenti nel dataset e che hanno una trasmissione di tipo
uguale o inferiore a quello indicato sull'ascissa. Ad esempio, il primo
segmento orizzontale del grafico rappresenta il numero di automobili con
trasmissione "manual", mentre il secondo segmento orizzontale
rappresenta il numero di automobili con trasmissione "manual" o "auto".

#### Grafico a torta

```{r}
freqRel <- table (mpg$fl )/ length (mpg$fl)
perc <- freqRel*100
perc <- round(perc,1)
LabelF <- c("Normal_gas", "Diesel", "Elettricity", "Premium_Gas", "Regular_gas") 
LabelF <- paste(LabelF, perc)
LabelF <- paste(LabelF, "%", sep = "")
pie ( perc , label = LabelF , col = rainbow ( length ( LabelF )), main = "Valori percentuali ")
```

#### Distribuzioni delle frequenze relative marginali

In R per calcolare la distribuzione delle frequenze relative congiunte
si può utilizzare il comando prop.table(nomeTabella) e da questa
ricavare le distribuzioni delle frequenze relative marginali.

```{r}
# Creazione del dataframe contente le due variabili categoriali fl e drv
drv_fl <- table(mpg$fl,mpg$drv)

# frequenze relative congiunte
freq_drv_fl <- prop.table(drv_fl)

# distribuzione delle frequenze relative marginali del tipo di carburante
margin.table (freq_drv_fl, 1)

# distribuzione delle frequneze relative marginali del tipo di trazione
margin.table (freq_drv_fl, 2)

```

Conoscendo la distribuzione delle frequenze relative congiunte e la
distribuzione delle frequenze relative marginali è possibile calcolare
la distribuzione delle frequenze relative di Y (tipo di trazione)
condizionata dalle modalità assunte da X (tipo di carburante) e
viceversa.

```{r}
# distribuzione delle frequenze relative condizionate f(j/i)
prop.table(freq_drv_fl, 1)

# distribuzione delle frequenze relative condizionate f(i/j)
prop.table(freq_drv_fl, 2)

```

Nel primo caso la somma degli elementi di ogni riga è unitaria; invece,
nel secondo caso la somma degli elementi di ogni colonna è unitaria.

Si dice che le variabili $X$ e $Y$ sono indipendenti se la frequenza
relativa congiunta si fattorizza come il prodotto delle due frequenze
relative marginali, ossia se risulta:

$$f_{ij} = f_{i}.f_{j}$$ con

$$(i=1,2,...,h;j=1,2,...,k).$$

Questa circostanza si verifica molto raramente sui dati reali

#### Grafici per le frequenze assolute congiunte

Una tabella di contingenza può essere rappresentata mediante un grafico
con rettangoli costituito da $h × k$ rettangoli. L'area totale dei
rettangoli è proporzionale al numero di casi. Il rettangolo in posizione
$(i, j)$ rappresenta l'elemento nella stessa posizione nella tabella di
contingenza e la sua area rappresenta il peso relativo della coppia di
modalità di $X$ e $Y$ all'interno della distribuzione congiunta.

In R, se si associa $table(X, Y)$ alla variabile $Z$, la
rappresentazione tramite rettangoli di una tabella di contingenza si può
realizzare con la funzione $plot(Z)$.

```{r}
plot(freq_drv_fl,col = "white", main = "Mosaic plot")
```

Si nota che sono presenti soltanto dodici rettangoli pieni e tre
rettangoli vuoti corrispondenti alle coppie la cui frequenza è nulla.

Talvolta è preferibile rappresentare la tabella di contingenza mediante
un grafico a barre sovrapposte. Il numero di barre è pari al numero
delle modalità delle colonne della tabella di contingenza. Inoltre,
all'interno di ciascuna barra sono rappresentate una sopra l'altra in
altezza le frequenze di ciascuna modalità delle righe della tabella di
contingenza. Sull'asse delle ordinate sono indicate le frequenze
(assolute o relative).

In R tale grafico può essere realizzato tramite la funzione barplot(Z).

```{r}
drv_fl_fl <- table(mpg$fl,mpg$drv)
barplot(drv_fl_fl, main = "Frequenza assoluta congiunta", legend = c("Gasolio normale", "Diesel", "Elettricità", "Gasolio premium", "Gasolio regolare"), col = c("yellow","brown","black","red","green"))
```

#### Grafici per le frequenze assolute marginali

Per ottenere il grafico della distribuzione marginale relativa al tipo
di trazione basta utilizzare il comando seguente che produce il grafico
a bastoncini.

```{r}
plot (margin.table(drv_fl, 2), main = " Frequenza assoluta marginale del tipo di trazione ", col =1:2)

```

che produce il grafico a bastoncini

```{r}
barplot(margin.table(drv_fl ,2), main = "Frequenza assoluta marginale del tipo di trazione", col = c(1:3)) 

```

#### Grafici per le frequenze relative condizionate

Ѐ possibile rappresentare graficamente le *frequenze relative
condizionate* utilizzando nuovamente la funzione barplot().

Nel seguente grafico illustreremo la distribuzione delle frequenze
relative condizionate del tipo di trazione fissato il tipo di carburante
utilizzando un grafico a barre appaiate ottenuto tramite le seguenti
linee di codice:

```{r}
drv_fl_drv <- table(mpg$drv,mpg$fl)
barplot(prop.table(drv_fl_drv ,2), beside = TRUE, main = " Frequenza relativa condizionata f(tipo di trazione|tipo di carburante)", legend = c("Trazione integrale", "Trazione anteriroe", "Trazione posteriore"), col =c(1:3) )
```

abbiamo utilizzato l'opzione *beside = TRUE* che permette di ottenere al
posto di un grafico a barre sovrapposte un grafico a barre appaiate,
ognuna delle quali indica la frequenza relativa condizionata
dell'ordinata nota l'ascissa. Si nota che la somma delle frequenze
relative condizionate relative alle ordinate è unitaria per ogni fissata
modalità delle ascisse.

### Variabile Class

La variabile Class rappresenta la classe di dimensioni dell'automobile.

#### Barplot

```{r}
p23 <- ggplot(data = mpg, mapping = aes(class)) + 
  geom_bar(fill = "white", col = "black") + ylab("Fuel")

p23 <- p23 + theme(panel.background = element_rect(fill = '#f0e2a8', color = '#9a8262'), 
               panel.grid.major = element_line(color = '#f0e2a8', linetype = 'longdash'),
               panel.grid.minor = element_line(color = '#fff68f', size = 0.7,linetype = "dotdash")) 

p23
```

Dall'istogramma possiamo notare che ci sono molti veicoli *suv* nel
nostro dataset, l'altra classe di veicoli molto frequente è *compact* e
*midsize*

# Modello di regressione lineare

Il dataset "mpg" fornito con il pacchetto **`ggplot2`** in R potrebbe
essere adeguato per eseguire un'analisi di regressione lineare multipla,
a seconda della domanda di ricerca o dell'ipotesi che vogliamo
verificare. La regressione lineare multipla è un modello statistico che
permette di indagare le relazioni tra più variabili indipendenti
(chiamate anche "predictor") e una variabile dipendente (chiamata anche
"risposta").

Per eseguire un'analisi di regressione lineare multipla, è importante
che il dataset contenga almeno una variabile dipendente e due o più
variabili indipendenti. Nel dataset "mpg", le variabili "cty" (consumo
di carburante in città) e "hwy" (consumo di carburante in autostrada)
potrebbero essere utilizzate come variabile dipendente, mentre le altre
variabili del dataset (ad esempio, "manufacturer", "displ", "year",
"cyl", "trans", "drv" e "class") potrebbero essere utilizzate come
variabili indipendenti.

Ricordiamo che, per eseguire un'analisi di regressione lineare multipla,
è importante che i dati soddisfino alcune assunzioni statistiche, come
la linearità e la varianza costante. Se queste assunzioni non sono
soddisfatte, potrebbe essere necessario trasformare o selezionare le
variabili o utilizzare un modello di regressione alternativo.

Dato che lo scopo è quello di prevedere il consumo di carburante in base
alle altre caratteristiche del veicolo (ad esempio, il volume del
motore, il tipo di trasmissione o il tipo di carburante utilizzato),
consideriamo l'utilizzo di un modello di regressione. Esistono diverse
varianti di modelli di regressione, come ad esempio la regressione
lineare semplice o la regressione multipla. In questo caso dato che ci
sono molte variabili che andranno ad influire sulla variabile dipendente
utilizzeremo il modello di regressione lineare multiplo.

Per costruire un modello di regressione lineare multipla, è necessario
avere una sufficiente quantità di dati che includano le variabili
indipendenti e la variabile dipendente per ciascuna osservazione. È
quindi possibile utilizzare questi dati per addestrare il modello e
quindi utilizzarlo per fare previsioni sulla variabile dipendente per
nuove osservazioni.

Se si definisce un data frame $dfm$, contenente n osservazioni delle p +
1 variabili $Y, X_1, X_2, . . . , X_p$, allora $cov(dfm)$ e $cor(dfm)$
forniscono due matrici di dimensioni (p + 1) · (p + 1) i cui elementi
solo le covarianze e le correlazioni tra coppie di variabili. In
particolare, tali matrici sono simmetriche; la matrice delle covarianze
contiene sulla diagonale principale la varianza delle singole colonne
del data frame, mentre la matrice delle correlazioni contiene il numero
1 sulla diagonale principale. La matrice di correlazione evidenzia tutte
le correlazioni lineari tra le coppie di variabili, ossia misura la
forza del legame di natura lineare esistente tra tutte le coppie di
variabili quantitative.

La funzione seguente ci permette di selezionare solo le variabili
numeriche dunque le variabili di cui andremo a calcolare la correlazione
e la covarianza.

```{r}
dfm <- mpg %>% 
  select_if(is.numeric)

```

### Covarianza

La covarianza (cov) è una misura della correlazione tra due variabili.
Indica se le due variabili cambiano in modo simile o in modo opposto e
in che misura cambiano insieme.

Assegnato un campione bivariato
$(x_1, y_1), (x_2, y_2), . . . , (x_n, y_n)$ di una variabile
quantitativa bidimensionale $(X, Y )$, siano $x$ e $y$ rispettivamente
le medie campionarie di $x_1, x_2, . . . , x_n$ e di
$y_1, y_2, . . . , y_n$. La covarianza campionaria tra le due variabili
$X$ e $Y$ è così definita:

$$
C_{xy} = \frac{1}{n-1} \sum_{i=1}^n (x_i - \overline x) (y = \overline y)
$$

con $$(n = 2,3,...)$$

La covarianza campionaria può avere segno positivo, negativo o nullo.
Quando $C_{xy} > 0$ si dice che le variabili sono correlate
positivamente, se $C_{xy} < 0$ le variabili sono correlate negativamente
e, infine, se $C_{xy} = 0$ le variabili sono non correlate.

In questo caso la matrice delle covarianze campionarie è

```{r}
cov(dfm)

```

### Correlazione

Assegnato un campione bivariato
$(x_1, y_1), (x_2, y_2), . . . , (x_n, y_n)$ di una variabile
quantitativa bidimensionale $(X, Y)$, siano $x$ e $sx$ la media
campionaria e la deviazione standard campionaria di
$x_1, x_2, . . . , x_n$ ed inoltre siano $y$ e $sy$ la media campionaria
e la deviazione standard campionaria di $y_1, y_2, . . . , y_n$. Il
coefficiente di correlazione campionario tra le due variabili $X$ e $Y$
è così definito:

$$
r_{xy} = \frac{C_{xy}}{s_x s_y}
$$

Si nota che il coefficiente di correlazione campionario

-   è un indice adimensionale;

-   non fa distinzione tra variabile dipendente e variabile
    indipendente, ossia $r_{xy} = r_{yx}$;

-   può essere calcolato soltanto se entrambe le variabili sono
    quantitative;

-   non cambia al variare dell'unità di misura con cui sono espresse le
    variabili;

-   è fortemente influenzato dalla presenza di eventuali valori anomali,
    così come accade per la media campionaria e la varianza campionaria.

La correlazione (cor) è una misura della relazione lineare tra due
variabili. Indica se c'è una relazione lineare tra le due variabili e in
che direzione va la relazione. La correlazione può assumere valori
compresi tra -1 e 1.

Il coefficiente di correlazione campionario ha lo stesso segno della
covarianza. Quando:

-    $r_{xy} > 0$ si dice che le variabili sono correlate positivamente

-    $r_{xy} < 0$ le variabili sono correlate negativamente

-    $r_{xy} = 0$ le variabili sono non correlate.

In questo caso la matrice delle correlazioni campionarie è

```{r}
cor(dfm)

```

Osservando i valori della covarianza e della correlazione possiamo
notare che le variabili *displ* e *cyl* sono unite da un forte legame
lineare, a differenza delle variabili *displ* e *cty*, *hwy* le quali
sono correlate ma negativamente. La variabile *cyl* è molto correlata
con *displ* ed è correlata negativamente con *cty* e *hwy*. Infine
osservando i valori di *year* possiamo affermare che è correlata in modo
molto debole con le altre variabili.

Per avere un'ulteriore conferma della forte correlazione tra la
variabile *hwy* e *cty* (0.95) rappresentiamo tale relazione in un
diagramma a dispersione:

```{r}
plot(mpg$hwy ,mpg$cty ,main =" Retta di regressione ", xlab="hwy",ylab="cty", col ="red ")
abline (lm( mpg$cty ~ mpg$hwy), col =" blue")

```

Dal grafico è evidente che le due variabile sono fortemente legate
linearmente, infatti lo scostamento delle osservazioni dalla retta di
regressione lineare (retta interpolante ascendente) è minimo.

La funzione *pairs()* è in grado di visualizzare in un'unica finestra
grafica una pluralità di scatterplot ottenuti mettendo in relazione
tutte le coppie di variabili quantitative definite all'interno di un
data frame.

```{r}
pairs(dfm,  main = "Scatterplot per le coppie di variabili", col ="black")
```

### Train set e test set

Il train set e il test set vengono utilizzati per valutare l'accuratezza
di un modello di regressione. Il train set viene utilizzato per
addestrare il modello, mentre il test set viene utilizzato per fare
previsioni sulla variabile dipendente e quindi per valutare
l'accuratezza del modello.

```{r}
# Divisione del dataset mpg in un set di training (80%) e un set di test (20%)
partizioni <- createDataPartition(mpg$cty, p = 0.8, list = FALSE)

# Creazione del set di training utilizzando le partizioni ottenute
train_set <- mpg[partizioni, ]

# Creazione del set di test escludendo le partizioni utilizzate per il set di training
test_set <- mpg[-partizioni, ]

```

## Modello di regressione lineare multiplo

Il modello di regressione lineare multipla è un tipo di modello di
regressione che viene utilizzato per prevedere una variabile dipendente
(chiamata anche variabile risposta o target) in base alla relazione con
una o più variabili indipendenti (chiamate anche variabili esplicative o
predictor). Il modello di regressione lineare multipla assume che ci sia
una relazione lineare tra la variabile dipendente e le variabili
indipendenti.

La regressione lineare multipla viene solitamente utilizzata quando ci
sono più di una variabile indipendente che potrebbero influire sulla
variabile dipendente. Ad esempio, potresti utilizzare il modello di
regressione lineare multipla per prevedere il consumo di carburante di
un'automobile (variabile dipendente) in base al volume del motore
(variabile indipendente), al tipo di trasmissione (variabile
indipendente) e al tipo di carburante utilizzato (variabile
indipendente).

```{r}
modello <- lm(cty ~ displ + trans + fl + cyl + drv, data = train_set)
summary(modello)

```

Nel modello di regressione lineare multiplo si è interessati a
sottoporre a verifica l'ipotesi nulla, la quale equivale a dire che la
variabile $X_j$ non influenza la variabile $Y$.

-   $H0 : βj = 0$

-   $H1 : βj ≠ 0$

Se l'ipotesi nulla è vera, la statistica t è :
$$t = \frac{(\overline \beta_{j})}{s . \sqrt(c_{}jj)} \sim t_{n-p-1}$$

Fissato un livello di significatività $\alpha$ si determina il valore
soglia $t_{\alpha/2}$ tale che:
$$P(|T| > t_{\alpha/2})= P(T < -t_{\alpha/2})+P(T>t_{\alpha/2}) = \alpha$$
Si rifiuta l'ipotesi *nulla* se: $$ |t|>t_{\alpha/2}$$In alternativa, si
calcola il *p-value*: $$P(T > t)=2[1-F(t)]$$ dove *F(t)* è la funzione
di ripartizione della v.c. t-Student.

Con il seguente codice escludiamo le variabili indipendenti che non
influenzano la variabile dipendente, ovvero le variabili *trans* e *fl*.

```{r}
modello_aggiornato <- update(modello, ~ . - trans - fl)
summary(modello_aggiornato)

```

Osserviamo che i segni di entrambi i regressori *displ* e *cyl* sono
negativi; quindi essi hanno un effetto negativo sulla variabile *cty*
(all'aumentare di *displ* e *cyl* diminuisce *cty*). Ciò non vale per la
variabile *drv* la quale ha segno positivo. Si nota anche che il
regressore *displ* è prossimo allo zero indicando che non incide in modo
significativo sulla variabile dipendente.

Pertanto possiamo dedurre che sono 3 le variabili che contribuiscono a
definire la variabile dipendete *cty* (miglia per gallone) e sono:
*displ*, *cyl* e *drvf.*

#### Previsioni

Dopo aver stimato il modello di regressione possiamo prevedere i valori
della variabile dipendente su un set di dati che non è stato usato per
addestrare il modello.

```{r}
previsioni <- predict(modello_aggiornato, test_set)

```

#### Misure di accuratezza

Per valutare l'accuratezza delle previsioni del modello di regressione
lineare multipla, possiamo utilizzare diverse metriche di valutazione.
Ad esempio:

-   Errore quadratico medio (MSE): indica la deviazione media quadratica
    tra i valori previsti dal modello e i valori effettivi della
    variabile dipendente. Un valore di MSE piccolo indica che il modello
    fa previsioni accurate, mentre un valore di MSE grande indica che il
    modello fa previsioni meno accurate.

```{r}
MSE <- mean((test_set$cty - previsioni)^2)
MSE

```

-   Coefficiente di determinazione (R²): indica la quantità di varianza
    nella variabile dipendente che viene spiegata dal modello. Un valore
    di R² vicino a 1 indica che il modello spiega in modo accurato la
    varianza nella variabile dipendente, mentre un valore di R² vicino a
    0 indica che il modello non spiega in modo accurato la varianza
    nella variabile dipendente.

```{r}
modello_test <- lm(cty ~ displ + cyl + drv, data = test_set)
summary(modello_test)$r.squared

```

-   Errore assoluto medio (MAE): indica la deviazione media assoluta tra
    i valori previsti dal modello e i valori effettivi della variabile
    dipendente. Un valore di MAE piccolo indica che il modello fa
    previsioni accurate, mentre un valore di MAE grande indica che il
    modello fa previsioni meno accurate.

```{r}
MAE <- mean(abs(test_set$cty - previsioni))
MAE

```

Osservando le misure di accuratezza possiamo affermare che il modello
che abbiamo stimato è un buon modello ovvero è un modello che è in grado
di fare previsioni accurate della variabile dipendente utilizzando le
variabili indipendenti.

## Residui

In generale, esisteranno degli scostamenti (residui) tra le ordinate dei
punti $y_i$ (valori osservati) e i corrispondenti valori stimati
$\hat y_i$.

I residui sono così definiti:

$$
E_i = y_i - \hat y_i = y_i - (\alpha + \beta x_i)
$$

con $$(i = 1,2,...,n)$$

e mostrano di quanto si discostano i valori osservati $y_i$ dai valori
stimati $\hat y_i$ con la regressione lineare multipla. In R per
calcolare il vettore dei valori stimati
$(\hat y_1, \hat y_2, . . . , \hat y_n)$ tramite regressione lineare
multipla si utilizza la funzione:

```{r}
# Visualizza il vettore delle stime
fit <- fitted(lm(data = mpg,cty ~ displ + cyl + drv))

```

Invece, per calcolare il vettore dei residui $(E_1,E_2, . . . ,E_n)$ si
utilizza la funzione:

```{r}
# Visualizza i residui
residui <- resid(lm(data = mpg,cty ~ displ + cyl + drv))

```

L'analisi dei residui in un modello di regressione lineare multipla
consiste nel verificare se i residui, ovvero la differenza tra i valori
osservati e quelli previsti dal modello, seguono una distribuzione
normale e se sono distribuiti in modo casuale. Ciò è importante perché
una distribuzione normale e casuale dei residui indica che il modello è
adeguato alla relazione tra le variabili dipendenti e indipendenti.

Per eseguire un'analisi dei residui, è possibile utilizzare alcuni
strumenti come un grafico di istogramma dei residui, un grafico Q-Q plot
e un grafico di dispersione dei residui sui valori previsti.

Il grafico di istogramma dei residui mostra la distribuzione dei
residui, e dovrebbe essere simile ad una distribuzione normale. Il
grafico Q-Q plot mostra se i residui seguono una distribuzione normale,
in caso contrario i punti non si troverebbero sulla linea di
regressione. Infine il grafico di dispersione dei residui sui valori
previsti deve mostrare una distribuzione casuale, ovvero senza alcun
schema visibile.

Nella realtà, spesso i dati non seguono perfettamente una distribuzione
normale, ma è importante valutare se l'adesione al modello non sia
troppo lontana dai valori attesi.

Si può usare la funzione plot() per creare questi grafici, e in R si può
utilizzare la libreria **`ggplot2`**

```{r}
# Q-Q plot
qqnorm(modello_aggiornato$residuals)
qqline(modello_aggiornato$residuals, col = 2)

```

```{r}
# Scatterplot dei residui vs valori stimati
ggplot(train_set, aes(x = modello_aggiornato$fitted.values, 
                      y = modello$residuals))+
geom_point() +
ggtitle("Residui vs Valori previsti")+
geom_hline(yintercept = 0) +
xlab("Valori stimati") +
ylab("Residui")


```

```{r}
# Istogramma dei residui
ggplot(train_set, aes(modello_aggiornato$residuals)) + 
  geom_histogram(bins = 30, col = "black", fill = "white") +
  ggtitle("Istogramma dei residui") + xlab("Residui")

```

Come possiamo osservare dal grafico la distribuzione è leggermente
asimmetrica positiva a causa dei due outlier presenti dopo il valore
*x=10*

Se i residui non seguono una distribuzione normale e casuale, può essere
necessario modificare il modello, ad esempio aggiungendo o rimuovendo
delle variabili, o utilizzando una trasformazione delle variabili.

## Coefficiente di determinazione

Il coefficiente di determinazione in un modello di regressione lineare
multipla è il rapporto tra la varianza dei valori stimati tramite la
funzione di regressione multipla e la varianza i valori osservati della
variabile dipendente. Se si denota con $(y_1, y_2, . . . , y_n)$ il
vettore dei dati della variabile dipendente, con $\overline y$ la sua
media campionaria e con $(\beta y_1, \beta y_2, . . . , \beta y_n)$ i
valori stimati attraverso la funzione di regressione (la cui media
campionaria $\overline y$), il coefficiente di determinazione è:

$$ D^2 = \frac{\frac{1}{n-1}\sum^n_{i=1}(\hat y_i - \overline y_i)^2}{
\frac{1}{n-1}\sum^n_{i=1}(y_i - \overline y_i)^2} = 
\frac{\sum^n_{i=1}(\hat y_i - \overline y_i)^2}
{\sum^n_{i=1}(y_i - \overline y_i)^2}
$$

L'indice $D^2$ è adimensionale e risulta $0 ≤ D^2 ≤ 1$. Quando $D^2 = 0$
il modello di regressione multipla utilizzato non spiega per nulla i
dati. Invece, quando $D^2 = 1$ il modello di regressione multipla
utilizzato spiega perfettamente i dati. In R per calcolare l'indice
$D^2$ per la regressione lineare multipla basta utilizzare la funzione:

```{r}
summary(modello_aggiornato)$r.squared

```

Il coefficiente di determinazione è *0.725*, ossia il modello di
regressione multipla utilizzato spiega significativamente i dati.

# Analisi dei cluster

La cluster analysis (analisi di raggruppamento o dei gruppi) è uno
strumento molto utilizzato per raggruppare elementi rispetto a delle
caratteristiche, utilizzata ad esempio in finanza per identificare
investitori con preferenze simili e fare proposte di investimento
adeguate, o nelle scienze sociali per identificare individui con
tendenze sociali simili. La metodica è composta di diversi algoritmi,
ciascuno dei quali cerca di organizzare una matrice in sottogruppi
omogenei, o "cluster". Tuttavia, l'ipotesi fondamentale è che i dati
formino un insieme eterogeneo che dovrebbe suddividersi in gruppi
naturali, familiari agli esperti dell'area analizzata.

I metodi per raggruppare gli elementi si basano sulla somiglianza (o
dissomiglianza) degli item tra loro. Gli item simili sono quindi
trattati come classe o gruppo omogeneo. Gran parte dell'output di una
analisi dei cluster è visiva, con i risultati visualizzati usando
scatterplot, alberi, dendrogrammi, grafici a silhouette, ed altri
strumenti grafici.

Gli algoritmi di clustering (o di partizionamento) sono usualmente
suddivisi tra approcci gerarchici e non gerarchici; gli algoritmi
gerarchici sono a loro volta suddivisi tra metodi agglomerativi e
divisivi. I metodi gerarchici operano aggregando (o separando) tutti gli
item sequenzialmente. I metodi agglomerativi iniziano con ciascun item
che compone il suo proprio cluster; in seguito, vengono aggregati in
successione i cluster più "simili", fino ad ottenere un unico cluster.
Gli algoritmi di clustering divisivi operano in maniera opposta:
iniziano con tutti gli item che appartengono ad un unico cluster;
dividono quindi questo cluster in due cluster separati "internamente
omogenei", e via di seguito; al termine della procedura ciascun item
formerà il "suo" cluster.

In questo manuale presenterò per ora solo esempi sui metodi gerarchici
agglomerativi e non gerarchici, applicati a dati di tipo numerico.

In questa parte del corso vedremo quindi:

1.  Algoritmi di **Clustering Gerarchico (Agglomerativo) (HC)**;

2.  Algoritmi di **Clustering Non-Gerarchici (K-Means) (NHC)**;

## Cluster gerarchico

Il punto di partenza di ogni metodo di Clustering Gerarchico (HC),
quindi, è il calcolo della dissimilarità ("dissomiglianza"; o
"distanza", se vale la disuguaglianza triangolare) di ciascun item
rispetto a tutti gli altri. Quale definizione di distanza usare
(euclidea, Manhattan, Canberra, ecc.), spesso dipende dall'applicazione
specifica o è una scelta soggettiva. Alcune misure di distanza sono
appropriate solo per certi tipi di dato, mentre altre sono state
introdotte per raggruppare variabili (colonne di dati) invece che
osservazioni (righe di dati).

### Distanza e similarità

La somiglianza può essere definita mediante un coefficiente di
similarità $sij = s(Xi,Xj)$ oppure mediante una misura di distanza
$dij = d(Xi,Xj)$ tra due individui $Ii$ e $Ij$ $(i 6= j)$.

Mentre i coefficienti di similarità assumono valori compresi tra 0 e 1,
le misure di distanza possono assumere qualsiasi valore reale maggiore o
uguale a zero.

Una misura di similarità fornisce un valore numerico compreso tra 0 e 1
e permette di definire in modo quantitativo la somiglianza o differenza
tra due individui $Ii$ e $Ij$ , intendendo ovviamente con 0 l'assoluta
assenza e con 1 la massima presenza di somiglianza.

Le misure metriche di somiglianza invece sono soprattutto basate sulle
funzioni distanza tra i vettori delle caratteristiche. Una funzione a
valori reali $d(Xi,Xj)$ è detta funzione distanza se e soltanto se essa
soddisfa le seguenti condizioni:

1.  $d(Xi,Xj) = 0$ se e solo se $Xi = Xj$ , con $Xi$ e $Xj$ in $Ep$;

2.  $d(Xi,Xj) ≥ 0$ per ogni $Xi$ e $Xj$ in $Ep$;

3.  $d(Xi,Xj) = d(Xj ,Xi)$ per ogni $Xi$ e $Xj$ in $Ep$;

4.  $d(Xi,Xj) ≤ d(Xi,Xk) + d(Xk,Xj)$ per ogni $Xi$, $Xj$ e $Xk$ in $Ep$.

La proprietà *1* implica che $Xi$ è a distanza zero da se stesso e che
ogni due punti a distanza nulla debbono essere identici.

La proprietà *2* afferma che la funzione distanza è non negativa.

La proprietà *3* impone la simmetria richiedendo che la distanza tra
$Xi$ e $Xj$ deve essere la stessa della distanza tra $Xj$ e $Xi$.

La proprietà *4*, nota come disuguaglianza triangolare, richiede che la
distanza tra $Xi$ e $Xj$ debba essere sempre minore o uguale della somma
delle distanze di ognuno dei due vettori considerati da qualunque altro
terzo vettore $Xk$.

Uno strumento generale in ***R*** per il calcolo delle distanze è la
funzione `dist()`.

Innanzitutto creiamo una partizione selezionando il *10%* delle
osservazioni del campione totale:

```{r}
p_mpg <- createDataPartition(mpg$class, p = 0.1, list = FALSE)
part_mpg <- mpg[p_mpg, ]

```

Mediante lo scalamento e la standardizzazione si ottengono dei nuovi
dati le cui medie campionarie sono nulle e le varianze campionarie
unitarie. In seguito calcoliamo le matrici delle distanze.

Entrambe le metriche del valore assoluto e del massimo sono
computazionalmente semplici da calcolare con l'unica differenza che la
metrica di Chebycev coinvolge anche una procedura di ordinamento.

```{r}
mpg_std <- scale(part_mpg[,c(3,5,8,9)],center = TRUE,scale = TRUE)

## Metrica Euclidea
d <- dist(mpg_std, method = "euclidean",diag = TRUE, upper = TRUE)

## Metrica di Manhattan
d <- dist(mpg_std, method = "euclidean",diag = TRUE, upper = TRUE)

## Metrica di Chebycev
d <- dist(mpg_std, method = "euclidean",diag = TRUE, upper = TRUE)

```

### Metodi gerarchici

I metodi gerarchici di clustering eseguono una sequenza ordinata di
operazioni della stessa natura. Tali metodi sono distinti in
*agglomerativi* che procedono per aggregazioni successive delle unità
partendo da n gruppi formati da un singolo individuo e *divisivi* che
partono da un solo gruppo formato da tutte le unità e procedono a
divisioni successive fino a giungere a gruppi formati da una sola unità.

I metodi gerarchici hanno due vantaggi: quello di fornire una visione
completa dell'insieme in termini di distanza (o di coefficienti di
similarità) seppure condizionata dalla scelta del metodo seguito e
quello di non comportare la scelta a priori del numero di cluster oppure
la scelta a priori di parametri per la determinazione automatica del
loro numero. Invece, uno svantaggio di tali metodi è che essi non
consentono di riallocare gli individui che sono stati già classificati
ad un livello precedente dell'analisi.

I metodi *non gerarchici* di clustering consentono, a differenza delle
tecniche di tipo gerarchico, di riallocare gli individui già
classificati ad un livello precedente dell'analisi. A differenza dei
metodi gerarchici, l'obiettivo finale dei metodi non gerarchici è quello
di ottenere un'unica partizione degli n individui di partenza in
cluster. In molti metodi non gerarchici di clustering si assume che il
numero di cluster in cui suddividere l'insieme totale degli $n$
individui sia fissato a priori dal ricercatore, mentre in altri tale
numero è determinato nel corso dell'analisi.

L'obiettivo finale dei metodi gerarchici non \`e quello di ottenere una
singola partizione degli n individui di partenza, ma di ottenere una
sequenza di partizioni che possono essere rappresentate graficamente
mediante una struttura ad albero, detta dendrogramma, nella quale
sull'insieme delle ordinate sono riportati i livelli di distanza mentre
sull'asse delle ascisse sono riportati i singoli individui. Ad ogni
livello di distanza corrisponde una partizione, mentre ad ogni
partizione corrispondono infiniti livelli di distanza compresi tra
quelli che individuano due successive unioni o divisioni.

In ogni modo, dopo aver ottenuto la matrice di dissimilarità, per
applicare un clustering gerarchico si deve specificare come si vuole
siano calcolate le distanze tra gruppi di osservazioni (cluster) durante
le iterazioni dell'algoritmo di clustering stesso. Anche in questo caso
ci sono diverse scelte da fare. Tra queste, c'è la scelta del cosiddetto
metodo di linkage (legame):

single linkage ==\> (legame singolo) la distanza tra due gruppi è
definita come il valore più piccolo delle distanze tra gli item dei due
gruppi;

complete linkage ==\> (legame completo) la distanza tra due gruppi è
definita come il valore più grande di distanza tra gli item dei due
gruppi;

average linkage ==\> (legame medio) questo è un compromesso tra i due
precedenti approcci, ottenuto come la media delle corrispondenti
distanze.

centroid linkage ==\> (legame del centroide) In questo metodo la
distanza tra i gruppi è definita come la distanza tra i centroidi, ossia
tra le medie campionarie calcolate sugli individui appartenenti ai due
gruppi.

median linkage ==\> (legame della mediana) Il metodo della mediana è
simile a quello del centroide, con la differenza che la procedura è
indipendente dalla numerosità dei cluster. Infatti, quando due gruppi si
aggregano, il nuovo centroide è calcolato come la semisomma dei due
centroidi precedenti.

Nei metodi agglomerativi del legame singolo, del legame completo e del
legame medio si può utilizzare una qualsiasi misura di distanza. Invece,
nel metodo del centroide e nel metodo della mediana si considera la
distanza euclidea e si lavora con una matrice D(2) che contiene i
quadrati delle singole distanze euclidee.

```{r}
util_sl <- hclust(d, method = "single")
util_cl <- hclust(d, method = "complete")
util_al <- hclust(d, method = "average")
util_cent <- hclust(d, method = "centroid")

```

Una volta applicati i metodi di clustering come sopra, l'approccio
grafico standard per rappresentare la soluzione di un algoritmo
gerarchico agglomerativo è quello del dendrogramma, che rappresenta la
sequenza di fusioni successive dei diversi gruppi, nonché le distanze su
cui sono state prodotte le aggregazioni Un dendrogramma in ***R*** è
disponibile con il metodo `plot` per gli oggetti di classe (tipo)
`hclust`:

```{r}
op <- par(mfrow = c(2, 2))
plot(util_sl, labels = part_mpg$class, cex = .7,
        main = "Utilities data (single linkage)", xlab = "Utilities")
plot(util_cl, labels = part_mpg$class, cex = .7,
        main = "Utilities data (complete linkage)", xlab = "Utilities")
plot(util_al, labels = part_mpg$class, cex = .7,
        main = "Utilities data (average linkage)", xlab = "Utilities")
plot(util_cent, labels = part_mpg$class, cex = .7,
        main = "Utilities data (Ward)", xlab = "Utilities")

```

Come si vede, il metodo del legame singolo tende a creare grandi gruppi
aggiungendo in successione item a gruppi già creati (il cosiddetto
effetto di "concatenazione"). Gli altri tre metodi ritornano invece
risultati simili tra loro, con cluster più strutturati.

Il dendrogramma costruito con questo metodo ha i rami molto più lunghi
rispetto al dendrogramma ottenuto con il metodo del legame singolo
poiché i gruppi si formano a livelli di distanza maggiori.

Si nota che con il metodo del legame medio la suddivisione in cluster
non cambia rispetto al caso del legame singolo e del legame completo, ma
variano alcuni livelli di distanza relativi alle aggregazioni;

Una volta scelto il numero di gruppi (più avanti vedremo anche questo
aspetto), si può usare la funzione `cutree()` per ottenere a quale
gruppo (cluster) appartiene ciascun item:

```{r}
util_cl_m <- cutree(util_cl, k = 5)
# Calcola i valori di silhouette
sil <- silhouette(util_cl_m, d)
# disegna il silhouette
plot(sil)

```

Come si vede, il parametro `k` definisce il numero di gruppi che si
vogliono ottenere.\
L'appartenenza ai cluster, che otteniamo dalla chiamata della funzione
`cutree()`, è utile per produrre una profilazione dei cluster, cioè per
fornire una descrizione più dettagliata delle caratteristiche principali
dei cluster identificati. Un ulteriore approccio grafico per ricavare
l'appartenenza ai cluster è dato dalla funzione `rect.hclust()`; questa
aggiunge al dendrogramma dei rettangoli che mostrano i cluster
identificati. Il grafico che segue identifica 5 gruppi con legame
completo:

```{r}
plot(util_cl)
rect.hclust(util_cl, k = 5)

```

Il grafico qui sopra mostra i valori di silhouette per i singoli item.
Ogni barra orizzontale rappresenta il valore di silhouette (sisi) di un
item all'interno del suo cluster assegnato. sisi è sempre compreso tra
-1 e 1. Un valore di sisi prossimo a 1 indica che l'item è assegnato ad
un cluster che "lo rappresenta" molto bene. Un valore di sisi prossimo a
-1 indica che l'item ii-mo è più simile ad item che appartengono ad
altri cluster vicini. Un sisi prossimo a zero indica che l'item ii-mo si
trova in una posizione sostanzialmente intermedia (cioè, sul bordo) tra
due o più cluster.

### Screeplot

Un metodo euristico per scegliere una buona partizione del dendrogramma
considera una procedura empirica consistente nel costruire un grafico,
detto screeplot. In esso si pongono sull'asse delle ordinate i numeri di
gruppi ottenibili con il metodo gerarchico e sull'asse delle ascisse le
distanze a cui avvengono le successive aggregazioni tra i gruppi. Se nel
passaggio da k gruppi a k − 1 gruppi si registra un forte incremento
della distanza di aggregazione è consigliabile tagliare il dendrogramma
in k gruppi.

Occorre infine sottolineare che lo screeplot è un metodo empirico che
realizza un grafico basato sulle altezze a cui sono avvenute le
aggregazioni in un metodo gerarchico e quindi non sempre fornisce il
numero adeguato di cluster in cui suddividere gli individui. Inoltre, è
preferibile non utilizzare lo screeplot nel metodo del centroide e della
mediana. Per la suddivisione in cluster in un metodo gerarchico è sempre
preferibile ricorrere alle misure di non omogeneità statistiche di cui
si serviranno, come vedremo, anche i metodi non gerarchici.

### Cluster non gerarchico

L'obiettivo dei metodi non gerarchici \`e quello di ottenere un'unica
partizione degli n individui di partenza in cluster. A differenza dei
metodi gerarchici, in tali tecniche è consentito riallocare gli
individui già classificati ad un livello precedente dell'analisi.

Gli algoritmi di tipo non gerarchico procedono, data una prima
partizione, a riallocare gli individui nel gruppo con centroide più
vicino, fino a che per nessun individuo si verifica che sia minima la
distanza rispetto al centroide di un gruppo diverso da quello a cui esso
appartiene. Il metodo più utilizzato prende il nome di k-means ed è
dovuto a Hartigan e Wong1. Tale metodo richiede che il numero di cluster
sia specificato a priori e fornisce in output un'unica partizione.

I vantaggi del metodo k-means sono la velocità di esecuzione dei calcoli
e l'estrema libertà che viene lasciata agli individui di raggrupparsi e
allontanarsi. Uno svantaggio è invece che la classificazione finale può
essere influenzata dalla scelta iniziale dei k vettori delle
caratteristiche come punti di riferimento, dall'ordine in cui sono presi
tali vettori e naturalmente dalle proprietà geometriche dei vettori
delle misure.

Dato un numero preassegnato *k* di gruppi, i metodi di clustering non
gerarchico (NHC) cercano la paritizione dei dati ("righe" o item) in *k*
cluster in maniera tale che gli item entro ciascun cluster o gruppo
siano quanto possibile simili tra loro, mentre gli item appartenenti a
cluster diversi siano quanto possibile diversi.

Un possibile approccio per ottenere questo risultato potrebbe passare
attraverso l'elencazione di tutti i possibili raggruppamenti in *k*
gruppi costruibili con gli item e quindi scegliere come migliore
soluzione il raggruppamento che ottimizza un qualche criterio
predefinito. Sfortunatamente, un tale approccio diventerebbe rapidamente
inapplicabile, specialmente per grandi dataset, poiché richiederebbe una
quantità enorme di tempo macchina e di spazio di memoria. Di conseguenza
tutte le tecniche di clustering disponibili sono iterative e operano
solo su un numero molto ristretto di enumerazioni.

Tra i molti algoritmi di clustering non gerarchici sviluppati finora, il
più popolare è il K-means. Nella sua implementazione fondamentale,
l'algoritmo K-means inizia assegnando gli item a uno dei *k* cluster
predeterminati e quindi calcolando i *k* centroidi di gruppo, oppure
pre-specificando i *k* centroidi di gruppo. I centroidi pre-specificati
possono essere item selezionati casualmente oppure possono essere
ottenuti "tagliando" un dendrogramma ad una altezza appropriata.\
In seguito, tramite una procedura iterativa, l'algoritmo cerca di
minimizzare la somma dei quadrati entro gruppi (WGSS) su tutte le
variabili, riassegnando ("spostando") gli item sui diversi cluster. La
procedura si ferma quando non si ottengono miglioramenti di WGSS con
ulteriori riassegnamenti.

La soluzione così ottenuta può non essere unica: l'algoritmo potrebbe
trovare solo un minimo locale di WGSS. Si suggerisce pertanto di
lanciare più volte l'algoritmo con assegnazioni casuali iniziali
differenti degli item ai *k* cluster (oppure selezionando casualmente i
*k* centroidi iniziali), così da trovare un probabile minimo globale di
WGSS e, quindi, la migliore soluzione di clustering basata su *k*
cluster.

Se calcoliamo prima le varianze delle variabili troviamo i seguenti:

```{r}
sapply(part_mpg[,c(3,5,8,9)], var)

```

Le varianze sono molto diverse, e l'uso del K-means sui dati grezzi
potrebbe fornire risultati poco utili perché "dominati" dalle
caratteristiche più variabili. Come nel caso del clustering gerarchico,
quindi, dovremmo normalizzare i dati in qualche modo; in questo caso
scegliamo di normalizzare ogni variabile dividendone i valori per il
rispettivo range.

```{r}
# calcola il range di ogni variabile
rge <- sapply(part_mpg[,c(3,5,8,9)], function(x) diff(range(x)))
# Divide ogni valore di ogni variabile per il suo range
mpg_s <- sweep(x = part_mpg[,c(3,5,8,9)], MARGIN = 2, STATS = rge, FUN = "/")
# Calcola la varianza di tutte le variabili "normalizzate"
sapply(mpg_s, var)

```

Adesso sono molto più confrontabili. Possiamo quindi procedere con il
clustering dei dati normalizzati. Dapprima tracciamo i valori di WGSS
per soluzioni di raggruppamento con un numero di cluster che varia tra 1
e 8 per vedere se possiamo ottenere indicazioni sul numero di gruppi
(che usualmente non è noto a priori). Il grafico può essere ottenuto
come segue:

```{r}
k_max <- 8
wss <- sapply(1:k_max,
              function(k,data) kmeans(data, centers = k)$tot.withinss,
              data=mpg_s)
ggp <- ggplot(data = data.frame(x=1:k_max, y=wss), mapping = aes(x=x,y=y)) +
  geom_point(colour = "red") +
  geom_line(colour = "blue") +
  xlab("Numero di gruppi") + 
  ylab("Somma dei quadrati entro gruppi (WGSS)")
print(ggp)

```

Mano a mano che il numero di gruppi aumenta, la somma dei quadrati
necessariamente si riduce; se si presenta un "gomito" nel grafico,
questo potrebbe essere indicativo della soluzione più utile che
l'analista dovrebbe osservare in dettaglio. Nel nostro caso un possibile
"gomito" (anche se non particolarmente evidente) potrebbe essere nella
soluzione con tre gruppi.\
Analizzeremo quindi questa soluzione. Le medie di gruppo per questa
soluzione sono calcolabili tramite:

```{r}
km_3 <- kmeans(mpg_s, centers = 3)
km_3$centers * rge

```

Volendo, possiamo provare l'indice di Calinski-Harabasz anche con il
clustering non gerarchico, per trovare il numero "ottimale" di cluster:

```{r}
require(clusterSim)
minC <- 2
maxC <- 10
res <- sapply(minC:maxC,
              function(nc, data) index.G1(data, kmeans(data,centers = nc)$cluster),
              data = mpg_s)
ggp <- ggplot(data=data.frame(x=2:(length(res)+1), y= res), mapping = aes(x=x,y=y)) + 
  geom_point() + 
  geom_line() +
  xlab("Numero di cluster") +
  ylab("Statistica pseudo-F di Calinski-Harabasz")
print(ggp)

```

Questo indice fornisce anche in questo caso una chiara indicazione che
il numero di cluster da scegliere debba essere uguale a 3.

Per visualizzare i cluster, possiamo utilizzare il pacchetto ggplot2 per
creare un grafico a dispersione dei dati con i punti colorati in base al
cluster a cui appartengono:

```{r}
ggplot(part_mpg[,c(3,5,8,9)], aes(x = displ, y = cty, color = km_3$cluster)) +
  geom_point()

```

In conclusione, i metodi gerarchici presentano un evidente vantaggio dal
punto di vista computazionale rispetto ai metodi di enumerazione
completa; tuttavia risultano sensibili a vettori delle caratteristiche
anomali e non consentono di modificare la configurazione raggiunta,
ossia una volta che un individuo è stato attribuito ad un cluster
permane al suo interno per sempre. I metodi non gerarchici non
presentano questo problema poiché consentono di riallocare gli individui
precedentemente classificati, ma richiedono una scelta opportuna della
configurazione iniziale.
